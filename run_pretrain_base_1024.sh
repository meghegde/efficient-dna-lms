nohup torchrun --nproc_per_node=2 pretrain_elc_bert.py --model_variant="base" --input_path='./data/processed/hg38_sequences_len_1024.txt' --vocab_path='InstaDeepAI/nucleotide-transformer-500m-human-ref' --learning_rate=1e-5 --batch_size=4 --seq_length=1024 --output_dir='./checkpoints/elc-bert-base' &
